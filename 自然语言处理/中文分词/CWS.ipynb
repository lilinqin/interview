{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 中文分词\n",
    "数据预处理<br>\n",
    "1.全角变半角<br>\n",
    "2.将数字变成0，字母变成X，去除空格<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['他  说  ，  政府  面临  的  首要  任务  是  修改  税制  。',\n",
       "  '这  项  呼吁  是  在  ６月３０日  开幕  的  “  通古斯  问题  ９０周年  ”  国际  研讨会  上  发出  的  。',\n",
       "  '１６日  ２０时３０分  成功  地  定点  于  东经ang８７．５度  赤道  上空  。'],\n",
       " ['他说，政府面临的首要任务是修改税制。',\n",
       "  '这项呼吁是在６月３０日开幕的“通古斯问题９０周年”国际研讨会上发出的。',\n",
       "  '１６日２０时３０分成功地定点于东经ang８７．５度赤道上空。'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "# 数据\n",
    "data = ['他  说  ，  政府  面临  的  首要  任务  是  修改  税制  。', \n",
    "        '这  项  呼吁  是  在  ６月３０日  开幕  的  “  通古斯  问题  ９０周年  ”  国际  研讨会  上  发出  的  。',\n",
    "        '１６日  ２０时３０分  成功  地  定点  于  东经ang８７．５度  赤道  上空  。']\n",
    "data_origin = [''.join(x.split()) for x in data]\n",
    "data, data_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['他', '说', ',', '政府', '面临', '的', '首要', '任务', '是', '修改', '税制', '。'],\n",
       " ['这',\n",
       "  '项',\n",
       "  '呼吁',\n",
       "  '是',\n",
       "  '在',\n",
       "  '6月30日',\n",
       "  '开幕',\n",
       "  '的',\n",
       "  '“',\n",
       "  '通古斯',\n",
       "  '问题',\n",
       "  '90周年',\n",
       "  '”',\n",
       "  '国际',\n",
       "  '研讨会',\n",
       "  '上',\n",
       "  '发出',\n",
       "  '的',\n",
       "  '。'],\n",
       " ['16日', '20时30分', '成功', '地', '定点', '于', '东经ang87.5度', '赤道', '上空', '。']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 全角变半角\n",
    "def tohalfwidth(data):\n",
    "    new_data = list()\n",
    "    for sentence in data:\n",
    "        if sentence == '':\n",
    "            continue\n",
    "        new_sent = list()\n",
    "        words = sentence.split()\n",
    "        for word in words:\n",
    "            half_word = ''\n",
    "            for uchar in word:\n",
    "                inside_code = ord(uchar)\n",
    "                if inside_code == 12288:\n",
    "                    inside_code = 32\n",
    "                elif 65281 <= inside_code <= 65374:\n",
    "                    inside_code -= 65248\n",
    "                half_word += chr(inside_code)\n",
    "            new_sent.append(half_word)\n",
    "        new_data.append(new_sent)\n",
    "    return new_data\n",
    "\n",
    "\n",
    "data = tohalfwidth(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['他', '说', ',', '政府', '面临', '的', '首要', '任务', '是', '修改', '税制', '。'],\n",
       " ['这',\n",
       "  '项',\n",
       "  '呼吁',\n",
       "  '是',\n",
       "  '在',\n",
       "  '0月0日',\n",
       "  '开幕',\n",
       "  '的',\n",
       "  '“',\n",
       "  '通古斯',\n",
       "  '问题',\n",
       "  '0周年',\n",
       "  '”',\n",
       "  '国际',\n",
       "  '研讨会',\n",
       "  '上',\n",
       "  '发出',\n",
       "  '的',\n",
       "  '。'],\n",
       " ['0日', '0时0分', '成功', '地', '定点', '于', '东经X0度', '赤道', '上空', '。']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将数字变成0，字母变成X，去除空格\n",
    "def generalize(data):\n",
    "    rNUM = re.compile(r'(-|\\+)?(\\d+)([\\.|·/∶:]\\d+)?%?')\n",
    "    rENG = re.compile(r'[A-Za-z_.]+')\n",
    "    #rRomaGreece = re.compile(r'[\\u2160-\\u216f|\\u0370-\\u03FF]+')\n",
    "    new_data = list()\n",
    "    for sent in data:\n",
    "        new_sent = list()\n",
    "        for word in sent:\n",
    "            word = re.sub(r'\\s+', '', word)\n",
    "            word = re.sub(rNUM, '0', word)\n",
    "            word = re.sub(rENG, 'X', word)\n",
    "            #word = re.sub(rRomaGreece, 'X', word)\n",
    "            #word = re.sub(rCon, '-', word)\n",
    "            new_sent.append(word)\n",
    "        new_data.append(new_sent)\n",
    "    return new_data\n",
    "\n",
    "data = generalize(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['他', '说', '，', '政府', '面临', '的', '首要', '任务', '是', '修改', '税制', '。'],\n",
       " ['这',\n",
       "  '项',\n",
       "  '呼吁',\n",
       "  '是',\n",
       "  '在',\n",
       "  '６月３０日',\n",
       "  '开幕',\n",
       "  '的',\n",
       "  '“',\n",
       "  '通古斯',\n",
       "  '问题',\n",
       "  '９０周年',\n",
       "  '”',\n",
       "  '国际',\n",
       "  '研讨会',\n",
       "  '上',\n",
       "  '发出',\n",
       "  '的',\n",
       "  '。'],\n",
       " ['１６日', '２０时３０分', '成功', '地', '定点', '于', '东经ang８７．５度', '赤道', '上空', '。']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def postprocess(data_origin, data_seg):\n",
    "\n",
    "    # data_origin转半角\n",
    "    data_half = list()\n",
    "    for sentence in data_origin:\n",
    "        newsent = list()\n",
    "        for uchar in sentence:\n",
    "            inside_code = ord(uchar)\n",
    "            if inside_code == 12288:\n",
    "                inside_code = 32\n",
    "            elif inside_code >= 65281 and inside_code <= 65374:\n",
    "                inside_code -= 65248\n",
    "            newchar = chr(inside_code)\n",
    "            newsent.append(newchar)\n",
    "        data_half.append(''.join(newsent))\n",
    "\n",
    "    # print(data_half)\n",
    "    # print(data_seg)\n",
    "    # 泛化字符恢复\n",
    "    rNUM = re.compile(r'(-|\\+)?(\\d+)([\\.|·/∶:]\\d+)?(%)?')\n",
    "    rENG = re.compile(r'[A-Za-z_.]+')\n",
    "    index = 0\n",
    "    data_general_recover = list()  # 泛化恢复后的分词结果\n",
    "    for seg_line, origin_line in zip(data_seg, data_half):\n",
    "        index += 1\n",
    "        new_word_list = list()\n",
    "        list_NUM = list()\n",
    "        list_ENG = list()\n",
    "\n",
    "        list_NUM_i = 0\n",
    "        list_ENG_i = 0\n",
    "\n",
    "        for t in re.findall(rNUM, origin_line):\n",
    "            list_NUM.append(''.join(t))\n",
    "        for t in re.findall(rENG, origin_line):\n",
    "            list_ENG.append(''.join(t))\n",
    "        if index == 1453:\n",
    "            print(origin_line, list_NUM, list_ENG)\n",
    "        word_list = seg_line.strip().split()\n",
    "        for word in word_list:\n",
    "            new_word = list()\n",
    "            for i in range(len(word)):\n",
    "                c = word[i]\n",
    "                if c == '0':\n",
    "                    new_word.append(list_NUM[list_NUM_i])\n",
    "                    list_NUM_i += 1\n",
    "                elif c == 'X':\n",
    "                    new_word.append(list_ENG[list_ENG_i])\n",
    "                    list_ENG_i += 1\n",
    "                else:\n",
    "                    new_word.append(c)\n",
    "            new_word = ''.join(new_word)\n",
    "            new_word_list.append(new_word)\n",
    "        data_general_recover.append(new_word_list)\n",
    "\n",
    "    # 切分原始的全角文件\n",
    "    data_result = list()\n",
    "    for seg_list, line_origin in zip(data_general_recover, data_origin):\n",
    "        new_line = []\n",
    "        len_list = []\n",
    "        for item in seg_list:\n",
    "            len_list.append(len(item))\n",
    "\n",
    "        line_origin = line_origin.strip()\n",
    "        i = 0\n",
    "        for w_len in len_list:\n",
    "            new_line.append(line_origin[i:i + w_len])\n",
    "            i += w_len\n",
    "        data_result.append(new_line)\n",
    "    \n",
    "    return data_result\n",
    "\n",
    "data_seg = [' '.join(x) for x in data]\n",
    "data_result = postprocess(data_origin, data_seg)\n",
    "data_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['他', '说'],\n",
       "  ',',\n",
       "  ['政', '府', '面', '临', '的', '首', '要', '任', '务', '是', '修', '改', '税', '制'],\n",
       "  '。',\n",
       "  '\\n',\n",
       "  ['这', '项', '呼', '吁', '是', '在', '0', '月', '0', '日', '开', '幕', '的'],\n",
       "  '“',\n",
       "  ['通', '古', '斯', '问', '题', '0', '周', '年'],\n",
       "  '”',\n",
       "  ['国', '际', '研', '讨', '会', '上', '发', '出', '的'],\n",
       "  '。',\n",
       "  '\\n',\n",
       "  ['0',\n",
       "   '日',\n",
       "   '0',\n",
       "   '时',\n",
       "   '0',\n",
       "   '分',\n",
       "   '成',\n",
       "   '功',\n",
       "   '地',\n",
       "   '定',\n",
       "   '点',\n",
       "   '于',\n",
       "   '东',\n",
       "   '经',\n",
       "   'X',\n",
       "   '0',\n",
       "   '度',\n",
       "   '赤',\n",
       "   '道',\n",
       "   '上',\n",
       "   '空'],\n",
       "  '。',\n",
       "  '\\n'],\n",
       " [[0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ['他  说  ，  政府  面临  的  首要  任务  是  修改  税制  。', \n",
    "        '这  项  呼吁  是  在  ６月３０日  开幕  的  “  通古斯  问题  ９０周年  ”  国际  研讨会  上  发出  的  。',\n",
    "        '１６日  ２０时３０分  成功  地  定点  于  东经ang８７．５度  赤道  上空  。']\n",
    "data = generalize(tohalfwidth(data))\n",
    "data = [''.join(x) for x in data]\n",
    "# print(data)\n",
    "\n",
    "def split_single_data(data):\n",
    "    sents = list()\n",
    "    labels = list()\n",
    "    for sent in data:\n",
    "        Left = 0\n",
    "        sent = list(sent)\n",
    "        # print(sent)\n",
    "        # exit()\n",
    "        for idx,c in enumerate(sent):\n",
    "            # if c not in config['special_token']:\n",
    "            if len(re.sub('\\W','',c,flags=re.U))==0:\n",
    "                if idx > Left:\n",
    "                    sents.append(list(''.join(sent[Left:idx])))\n",
    "                    labels.append([0]*len(list(''.join(sent[Left:idx]))))\n",
    "                    sents.append(c)\n",
    "                else:\n",
    "                    sents.append(c)\n",
    "                Left = idx+1\n",
    "        if Left!=len(sent):\n",
    "            sents.append(list(''.join(sent[Left:])))\n",
    "            labels.append([0]*len(list(''.join(sent[Left:]))))\n",
    "        sents.append('\\n')\n",
    "    return sents, labels\n",
    "\n",
    "split_single_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    set_seed\n",
    ")\n",
    "\n",
    "bert_path = 'hfl/chinese-electra-180g-base-discriminator'\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "            bert_path\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 8170, 8452, 8148, 102]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ['他  说  ，  政府  面临  的  首要  任务  是  修改  税制  。', \n",
    "        '这  项  呼吁  是  在  ６月３０日  开幕  的  “  通古斯  问题  ９０周年  ”  国际  研讨会  上  发出  的  。',\n",
    "        '１６日  ２０时３０分  成功  地  定点  于  东经ang８７．５度  赤道  上空  。']\n",
    "# data = generalize(tohalfwidth(data))\n",
    "# data = [''.join(x) for x in data]\n",
    "encoded = tokenizer.encode('2009111')\n",
    "encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2693\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cc6d3d5f61bfe62bf184ea5ea0eac0593cecefcf5a700c232598549fb9e65d86"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('pt': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
